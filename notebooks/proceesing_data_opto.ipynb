{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_analysis_pkg.core import NeuralAnalysis\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your project folder\n",
    "project_folder_path ='/home/cresp1el-local/Documents/MATLAB/Data/lmc_project_v2/LED'\n",
    "# Initialize the NeuralAnalysis class with the project folder path\n",
    "analysis = NeuralAnalysis(project_folder_path)\n",
    "\n",
    "#uncomment if required\n",
    "# analysis.process_dat_file(project_folder_path) #process dat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.recording_results_df #show recording results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.process_MUA() #process MUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this dataframe to a csv file using the csv file path as the argument so you dont have to run the downsampling and filtering again\n",
    "# analysis.recording_results_df.to_csv(os.path.join(project_folder_path,'SpikeStuff/recording_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.extract_stimulation_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.stimulation_data_df #show stimulation data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.extract_spike_times() #detect spikes from MUA data using thresholding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.recording_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_firing_rates(recording_name, recording_results_df, stimulation_data_df, n_channels):\n",
    "    # Get the mua_data_path for the current recording to get the spike_data_path where the spike times are stored\n",
    "    mua_data_path = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'mua_data_path'\n",
    "    ].values[0]\n",
    "    \n",
    "    # Construct the spike_data_path from the mua_data_path\n",
    "    spike_data_path = mua_data_path.replace('_MUA.npy', '_spike_times.npy')\n",
    "    \n",
    "    # Step 1: Identify the time windows for stimulus_id = 8, which is an 8Hz signal \n",
    "    stim_data = stimulation_data_df[\n",
    "        (stimulation_data_df['recording_name'] == recording_name) & \n",
    "        (stimulation_data_df['stimulation_ids'] == 8)\n",
    "    ]\n",
    "    \n",
    "    # Step 2: Load the corresponding spike times\n",
    "    spike_data = np.load(spike_data_path, allow_pickle=True)\n",
    "    spike_times = spike_data['time']\n",
    "    spike_channels = spike_data['channel']\n",
    "    \n",
    "    # Get good and noisy channels for the current recording\n",
    "    good_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'good_channels'\n",
    "    ].values[0]\n",
    "    noisy_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'noisy_channels'\n",
    "    ].values[0]\n",
    "\n",
    "    # Step 3 & 4: Calculate and aggregate the firing rates\n",
    "    firing_rates = np.full((n_channels, len(stim_data)), np.nan) # Initialize with NaNs \n",
    "\n",
    "    for i, (onset, offset) in enumerate(zip(stim_data['onset_times'], stim_data['offset_times'])):\n",
    "        for ch in good_channels:\n",
    "            # Find spikes in the current channel and time window\n",
    "            condition = (spike_channels == ch) & (spike_times >= onset) & (spike_times <= offset)\n",
    "            spikes_in_window = spike_times[np.where(condition)]\n",
    "            \n",
    "            # Calculate the firing rate\n",
    "            firing_rate = len(spikes_in_window) / (offset - onset)\n",
    "            firing_rates[ch, i] = firing_rate\n",
    "    \n",
    "    # Step 5: Plotting the heatmap\n",
    "    plt.imshow(firing_rates, aspect='auto', cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar(label='Firing Rate (Hz)')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.xlabel('Trial')\n",
    "    plt.title('Firing Rate Heatmap for Stimulus ID = 8 Hz LED')\n",
    "    plt.yticks(range(n_channels), range(1, n_channels+1))  # Label y-axis with channel numbers\n",
    "    plt.show()\n",
    "    \n",
    "calculate_firing_rates('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_firing_rates('lmc_ch_1_3094_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_firing_rates('lmc_ch_1_3094_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_firing_rates('lmc_noch_1_3096_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_firing_rates('lmc_noch_1_3096_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def estimate_instantaneous_firing_rate(recording_name, recording_results_df, n_channels, bin_size=0.001, window_length=0.05, window_sd=0.005):\n",
    "    \"\"\"\n",
    "    Estimate the instantaneous firing rate by convolving the spike time series with a Gaussian window.\n",
    "\n",
    "    Parameters:\n",
    "    - recording_name (str): The name of the recording to process.\n",
    "    - recording_results_df (pd.DataFrame): The data frame containing the recording results.\n",
    "    - n_channels (int): The number of channels in the recording.\n",
    "    - bin_size (float): The bin size for discretizing the spike times, in seconds. Default is 1 ms (0.001 s).\n",
    "    - window_length (float): The length of the Gaussian window in seconds. Default is 50 ms (0.05 s).\n",
    "    - window_sd (float): The standard deviation of the Gaussian window in seconds. Default is 5 ms (0.005 s).\n",
    "    \n",
    "    Returns:\n",
    "    - firing_rate_estimates (ndarray): A 2D array where each row represents a channel and each column represents a time bin. The values represent the estimated firing rates in Hz.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the mua_data_path for the current recording to get the spike_data_path where the spike times are stored\n",
    "    mua_data_path = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'mua_data_path'\n",
    "    ].values[0]\n",
    "    \n",
    "    # Construct the spike_data_path from the mua_data_path\n",
    "    spike_data_path = mua_data_path.replace('_MUA.npy', '_spike_times.npy')\n",
    "    \n",
    "    # Step 1: Load the spike data\n",
    "    spike_data = np.load(spike_data_path, allow_pickle=True)\n",
    "    spike_times = spike_data['time']\n",
    "    spike_channels = spike_data['channel']\n",
    "\n",
    "    # Step 2: Determine the duration from the MUA data\n",
    "    mua_data = np.load(mua_data_path)\n",
    "    duration = mua_data.shape[0] / 10000  # Convert number of samples to seconds (assuming 10 kHz sampling rate)\n",
    "\n",
    "    # Step 3: Create a time vector with bins\n",
    "    time_vector = np.arange(0, duration, bin_size)\n",
    "\n",
    "    # Step 4: Create a spike train matrix with each row representing a channel and each column representing a time bin\n",
    "    spike_trains = np.zeros((n_channels, len(time_vector) - 1))\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        spike_times_ch = spike_times[spike_channels == ch]\n",
    "        spike_trains[ch, :] = np.histogram(spike_times_ch, bins=time_vector)[0]\n",
    "\n",
    "    # Step 5: Convolve the spike train with a Gaussian window to estimate the instantaneous firing rate\n",
    "    window_length_bins = int(window_length / bin_size)  # Convert window length from seconds to number of bins\n",
    "    window_sd_bins = window_sd / bin_size  # Convert window SD from seconds to number of bins\n",
    "    firing_rate_estimates = np.zeros_like(spike_trains)\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        firing_rate_estimates[ch, :] = gaussian_filter1d(spike_trains[ch, :], sigma=window_sd_bins)\n",
    "\n",
    "    return firing_rate_estimates\n",
    "\n",
    "#run the function\n",
    "#firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap\n",
    "plt.imshow(firing_rate_estimates, aspect='auto', cmap='hot', interpolation='nearest', extent=[0, firing_rate_estimates.shape[1], 0, firing_rate_estimates.shape[0]])\n",
    "plt.colorbar(label='Firing Rate (Hz)')\n",
    "plt.ylabel('Channel')\n",
    "plt.xlabel('Time (bins)')\n",
    "plt.title('Instantaneous Firing Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_psth(recording_name, recording_results_df, stimulation_data_df, n_channels, firing_rate_estimates, stim_id, bin_size=0.001):\n",
    "    \n",
    "    # Get the mua_data_path for the current recording to get the spike_data_path where the spike times are stored\n",
    "    mua_data_path = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'mua_data_path'\n",
    "    ].values[0]\n",
    "    \n",
    "    # Construct the spike_data_path from the mua_data_path\n",
    "    spike_data_path = mua_data_path.replace('_MUA.npy', '_spike_times.npy')\n",
    "    \n",
    "    # Step 1: Identify the time windows for the specified stimulus_id\n",
    "    stim_data = stimulation_data_df[\n",
    "        (stimulation_data_df['recording_name'] == recording_name) & \n",
    "        (stimulation_data_df['stimulation_ids'] == stim_id)\n",
    "    ]\n",
    "    \n",
    "    # Get good and noisy channels for the current recording\n",
    "    good_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'good_channels'\n",
    "    ].values[0]\n",
    "\n",
    "    # Find the minimum onset and maximum offset times to get a common time window for all trials\n",
    "    min_onset = stim_data['onset_times'].min() - 0.5  # 500 ms before the minimum onset\n",
    "    max_offset = stim_data['offset_times'].max() + 0.5  # 500 ms after the maximum offset\n",
    "\n",
    "    # Find the bins corresponding to the common time window\n",
    "    start_bin = int(min_onset / bin_size)\n",
    "    end_bin = int(max_offset / bin_size)\n",
    "\n",
    "    # Initialize arrays to accumulate the sums and counts for each bin\n",
    "    sum_psth = np.zeros((n_channels, end_bin - start_bin))\n",
    "    count_psth = np.zeros((n_channels, end_bin - start_bin))\n",
    "\n",
    "    # Loop through each trial to calculate the PSTH\n",
    "    for i, (onset, offset) in enumerate(zip(stim_data['onset_times'], stim_data['offset_times'])):\n",
    "        # Find the bins corresponding to the current time window\n",
    "        trial_start_bin = int((onset - 0.5) / bin_size)\n",
    "        trial_end_bin = int((offset + 0.5) / bin_size)\n",
    "\n",
    "        # Add the firing rate estimates to the sum and update the count in the relevant bins\n",
    "        sum_psth[:, trial_start_bin - start_bin : trial_end_bin - start_bin] += firing_rate_estimates[:, trial_start_bin:trial_end_bin]\n",
    "        count_psth[:, trial_start_bin - start_bin : trial_end_bin - start_bin] += 1\n",
    "    \n",
    "    # Calculate the mean PSTH by dividing the sum by the count\n",
    "    mean_psth = np.divide(sum_psth, count_psth, where=(count_psth!=0))\n",
    "\n",
    "    # Plotting the mean PSTH for each channel\n",
    "    time_bins = np.linspace(min_onset, max_offset, end_bin - start_bin)\n",
    "    plt.figure()\n",
    "    for ch in good_channels:\n",
    "        plt.plot(time_bins, mean_psth[ch, :])\n",
    "    \n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Firing Rate (Hz)')\n",
    "    plt.title(f'Mean PSTH for Stimulus ID = {stim_id}')\n",
    "    plt.show()\n",
    "\n",
    "#first get the firing rate estimates for the recording name\n",
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.n_channels)\n",
    "#run the function \n",
    "calculate_psth('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psth(recording_name, recording_results_df, stimulation_data_df, n_channels, firing_rate_estimates, stim_id=1, bin_size=0.001):\n",
    "    # Get the mua_data_path for the current recording\n",
    "    mua_data_path = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'mua_data_path'\n",
    "    ].values[0]\n",
    "    \n",
    "    # Step 1: Identify the time windows for the specified stimulus_id\n",
    "    stim_data = stimulation_data_df[\n",
    "        (stimulation_data_df['recording_name'] == recording_name) & \n",
    "        (stimulation_data_df['stimulation_ids'] == stim_id)\n",
    "    ]\n",
    "    \n",
    "    # Get good and noisy channels for the current recording\n",
    "    good_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'good_channels'\n",
    "    ].values[0]\n",
    "    noisy_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'noisy_channels'\n",
    "    ].values[0]\n",
    "\n",
    "    # Exclude noisy channels from good channels\n",
    "    good_channels = [ch for ch in good_channels if ch not in noisy_channels]\n",
    "\n",
    "    # Step 2 & 3: Aggregate the PSTH data\n",
    "    psth_duration_in_s = 1.5  # PSTH duration in seconds (1500 ms)\n",
    "    num_bins = int(psth_duration_in_s / bin_size)\n",
    "    sum_psth = np.zeros((n_channels, num_bins))  # Initialize with zeros\n",
    "    count_psth = np.zeros((n_channels, num_bins))  # Initialize with zeros\n",
    "\n",
    "    for i, (onset, offset) in enumerate(zip(stim_data['onset_times'], stim_data['offset_times'])):\n",
    "        for ch in good_channels:\n",
    "            # Find the bins corresponding to the current time window (from -500ms to +1000ms relative to the onset)\n",
    "            start_bin = int((onset - 0.5) / bin_size)\n",
    "            end_bin = int((onset + 1.0) / bin_size)\n",
    "            \n",
    "            # within your loop where you extract trial_psth\n",
    "            trial_psth = firing_rate_estimates[ch, start_bin:end_bin][:1500]\n",
    "            \n",
    "            #accumulate the sum and update the count in the relevant bins\n",
    "            try: \n",
    "                sum_psth[ch, :] += np.nan_to_num(trial_psth)\n",
    "                count_psth[ch, :] += np.isfinite(trial_psth)\n",
    "            except ValueError: \n",
    "                # If lengths are mismatched, extend trial_psth with its last value\n",
    "                if len(trial_psth) == len(sum_psth[ch, :]) - 1:\n",
    "                    trial_psth = np.append(trial_psth, trial_psth[-1])\n",
    "                    sum_psth[ch, :] += np.nan_to_num(trial_psth)\n",
    "                    count_psth[ch, :] += np.isfinite(trial_psth)\n",
    "                else:\n",
    "                    print(\"Unexpected mismatch in lengths\")\n",
    " \n",
    "    # Calculate the mean PSTH by dividing the sum by the count\n",
    "    mean_psth = np.divide(sum_psth, count_psth, where=(count_psth!=0))\n",
    "    \n",
    "    # Convert firing rate from spikes per bin to spikes per second (Hz)\n",
    "    mean_psth /= bin_size\n",
    "\n",
    "    # Create a time axis that spans from -500 ms to +1000 ms\n",
    "    time_axis = np.linspace(-500, 1000, num_bins)\n",
    "\n",
    "    # Step 4: Plotting the mean PSTH for each channel\n",
    "    plt.figure()\n",
    "    for ch in range(n_channels):\n",
    "        plt.plot(time_axis, mean_psth[ch, :])\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel('Firing Rate (Hz)')\n",
    "        plt.title(f'Channel {ch+1}')\n",
    "        plt.axvline(x=0, color='r', linestyle='--')  # Mark stimulus onset\n",
    "        plt.axvline(x=500, color='r', linestyle='--')  # Mark stimulus offset\n",
    "        plt.show()\n",
    "\n",
    "#run the function with the firing rate estimates\n",
    "calculate_psth('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.recording_results_df['recording_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_psth('lmc_ch_1_3094_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)\n",
    "\n",
    "calculate_psth('lmc_ch_1_3094_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_psth('lmc_ch_1_3094_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_psth('lmc_noch_1_3096_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_psth('lmc_noch_1_3096_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bootstrap_ci(data, n_bootstraps=1000, ci=0.99):\n",
    "    bootstrapped_means = []\n",
    "    for i in range(n_bootstraps):\n",
    "        random_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped_means.append(np.mean(random_sample))\n",
    "    lower = np.percentile(bootstrapped_means, (1-ci)/2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1+ci)/2 * 100)\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def calculate_psth_and_responsive_channels(recording_name, recording_results_df, stimulation_data_df, n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001):\n",
    "    # Initialization\n",
    "    prestimulus_CI = []\n",
    "    poststimulus_CI = []\n",
    "    responsive_channels = []\n",
    "    \n",
    "    # Existing data retrieval logic\n",
    "    mua_data_path = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'mua_data_path'\n",
    "    ].values[0]\n",
    "    \n",
    "    stim_data = stimulation_data_df[\n",
    "        (stimulation_data_df['recording_name'] == recording_name) & \n",
    "        (stimulation_data_df['stimulation_ids'] == stim_id)\n",
    "    ]\n",
    "    \n",
    "    good_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'good_channels'\n",
    "    ].values[0]\n",
    "    noisy_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'noisy_channels'\n",
    "    ].values[0]\n",
    "    \n",
    "    good_channels = [ch for ch in good_channels if ch not in noisy_channels]\n",
    "  \n",
    "    for ch in good_channels:\n",
    "        all_prestim_data = []\n",
    "        all_poststim_data = []\n",
    "        \n",
    "        for i, (onset, offset) in enumerate(zip(stim_data['onset_times'], stim_data['offset_times'])):\n",
    "            prestim_start_bin = int((onset - 0.6) / bin_size)\n",
    "            prestim_end_bin = int(onset / bin_size)\n",
    "            \n",
    "            poststim_start_bin = int(onset / bin_size)\n",
    "            poststim_end_bin = int((onset + 0.1) / bin_size)\n",
    "            \n",
    "            # this would be pooling the data from all trials for each channel which each bin is a time point of varying voltage\n",
    "            # prestim_data = firing_rate_estimates[ch, prestim_start_bin:prestim_end_bin]\n",
    "            # poststim_data = firing_rate_estimates[ch, poststim_start_bin:poststim_end_bin]\n",
    "            \n",
    "            # use the extend method if pooling from all trials for each channel\n",
    "            # all_prestim_data.extend(prestim_data)\n",
    "            # all_poststim_data.extend(poststim_data)\n",
    "            \n",
    "            prestim_data = np.mean(firing_rate_estimates[ch, prestim_start_bin:prestim_end_bin])\n",
    "            poststim_data = np.mean(firing_rate_estimates[ch, poststim_start_bin:poststim_end_bin])\n",
    "            \n",
    "            all_prestim_data.append(prestim_data)  # Use append here\n",
    "            all_poststim_data.append(poststim_data)  # Use append here\n",
    "        \n",
    "        # Perform bootstrap analysis for 99% CI on the pooled data\n",
    "        prestim_bootstrap = bootstrap_ci(np.array(all_prestim_data))\n",
    "        poststim_bootstrap = bootstrap_ci(np.array(all_poststim_data))\n",
    "        \n",
    "        # Print for debugging\n",
    "        print(f\"Channel {ch}: Pre-stim CI: {prestim_bootstrap}, Post-stim CI: {poststim_bootstrap}\")\n",
    "        \n",
    "        prestimulus_CI.append(prestim_bootstrap)\n",
    "        poststimulus_CI.append(poststim_bootstrap)\n",
    "        \n",
    "        if poststim_bootstrap[0] > prestim_bootstrap[1]:\n",
    "            responsive_channels.append(ch)\n",
    "    print(\"Responsive channels:\", responsive_channels)\n",
    "\n",
    "#run the function \n",
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.n_channels)\n",
    "calculate_psth_and_responsive_channels('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE UPDATED CODE...ned to confirm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data, n_bootstraps=1000, ci=0.99):\n",
    "    bootstrapped_means = []\n",
    "    for i in range(n_bootstraps):\n",
    "        random_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped_means.append(np.mean(random_sample))\n",
    "    lower = np.percentile(bootstrapped_means, (1-ci)/2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1+ci)/2 * 100)\n",
    "    return lower, upper\n",
    "\n",
    "def calculate_psth_and_responsive_channels(recording_name, recording_results_df, stimulation_data_df, n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001):\n",
    "    # Initialization\n",
    "    prestimulus_CI = []\n",
    "    poststimulus_CI = []\n",
    "    responsive_channels = []\n",
    "    \n",
    "    avg_firing_rates_for_responsive_channels = []\n",
    "    all_baseline_firing_rates = []\n",
    "    \n",
    "    # Existing data retrieval logic\n",
    "    mua_data_path = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'mua_data_path'\n",
    "    ].values[0]\n",
    "    \n",
    "    stim_data = stimulation_data_df[\n",
    "        (stimulation_data_df['recording_name'] == recording_name) & \n",
    "        (stimulation_data_df['stimulation_ids'] == stim_id)\n",
    "    ]\n",
    "    \n",
    "    good_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'good_channels'\n",
    "    ].values[0]\n",
    "    noisy_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'noisy_channels'\n",
    "    ].values[0]\n",
    "    \n",
    "    good_channels = [ch for ch in good_channels if ch not in noisy_channels]\n",
    "  \n",
    "    for ch in good_channels:\n",
    "        all_prestim_data = []\n",
    "        all_poststim_data = []\n",
    "        \n",
    "        for i, (onset, offset) in enumerate(zip(stim_data['onset_times'], stim_data['offset_times'])):\n",
    "            prestim_start_bin = int((onset - 0.2) / bin_size)\n",
    "            prestim_end_bin = int(onset / bin_size)\n",
    "            poststim_start_bin = int(onset / bin_size)\n",
    "            poststim_end_bin = int((onset + 0.08) / bin_size)\n",
    "            \n",
    "            prestim_data = np.mean(firing_rate_estimates[ch, prestim_start_bin:prestim_end_bin]) / bin_size\n",
    "            poststim_data = np.mean(firing_rate_estimates[ch, poststim_start_bin:poststim_end_bin]) / bin_size\n",
    "            \n",
    "            all_prestim_data.append(prestim_data)\n",
    "            all_poststim_data.append(poststim_data)\n",
    "        \n",
    "        prestim_bootstrap = bootstrap_ci(np.array(all_prestim_data))\n",
    "        poststim_bootstrap = bootstrap_ci(np.array(all_poststim_data))\n",
    "        \n",
    "        print(f\"Channel {ch}: Pre-stim CI: {prestim_bootstrap}, Post-stim CI: {poststim_bootstrap}\")\n",
    "        \n",
    "        prestimulus_CI.append(prestim_bootstrap)\n",
    "        poststimulus_CI.append(poststim_bootstrap)\n",
    "        \n",
    "        if poststim_bootstrap[0] > prestim_bootstrap[1]:\n",
    "            responsive_channels.append(ch)\n",
    "            avg_firing_rates_for_responsive_channels.append(np.mean(all_poststim_data))\n",
    "            all_baseline_firing_rates.extend(all_prestim_data)\n",
    "\n",
    "    print(\"Responsive channels:\", responsive_channels)\n",
    "    \n",
    "    single_waveform = np.mean(avg_firing_rates_for_responsive_channels)\n",
    "    baseline = np.mean(all_baseline_firing_rates)\n",
    "    percent_change = ((single_waveform - baseline) / baseline) * 100\n",
    "\n",
    "    print(f\"Single LED-evoked waveform: {single_waveform}\")\n",
    "    print(f\"Baseline: {baseline}\")\n",
    "    print(f\"Percent change relative to baseline: {percent_change}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.n_channels)\n",
    "calculate_psth_and_responsive_channels('lmc_ch_2_3093_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_ch_1_3094_rec1', analysis.recording_results_df, analysis.n_channels)\n",
    "calculate_psth_and_responsive_channels('lmc_ch_1_3094_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_ch_1_3094_rec2', analysis.recording_results_df, analysis.n_channels)\n",
    "calculate_psth_and_responsive_channels('lmc_ch_1_3094_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_noch_1_3096_rec1', analysis.recording_results_df, analysis.n_channels)\n",
    "calculate_psth_and_responsive_channels('lmc_noch_1_3096_rec1', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_estimates = estimate_instantaneous_firing_rate('lmc_noch_1_3096_rec2', analysis.recording_results_df, analysis.n_channels)\n",
    "calculate_psth_and_responsive_channels('lmc_noch_1_3096_rec2', analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, firing_rate_estimates, stim_id=8, bin_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.recording_results_df['recording_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.recording_results_df['recording_name'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.recording_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psth_pre_post(recording_name, recording_results_df, stimulation_data_df, n_channels, firing_rate_estimates, bin_size=0.001, pre_trials=30, post_trials=30):\n",
    "    # Get good and noisy channels for the current recording\n",
    "    good_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'good_channels'\n",
    "    ].values[0]\n",
    "    noisy_channels = recording_results_df.loc[\n",
    "        recording_results_df['recording_name'] == recording_name, \n",
    "        'noisy_channels'\n",
    "    ].values[0]\n",
    "\n",
    "    good_channels = list(set(good_channels) - set(noisy_channels))\n",
    "\n",
    "    for ch in good_channels:  # Loop through each channel\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))  # Create a 1x4 subplot for each channel\n",
    "\n",
    "        for stim_id in range(1, 5):  # Loop through each stimulation ID\n",
    "            ax = axs[stim_id - 1]  # Get the correct axes\n",
    "\n",
    "            # Separate the data into pre and post epochs based on the trial range specified\n",
    "            stim_data = stimulation_data_df[\n",
    "                (stimulation_data_df['recording_name'] == recording_name) & \n",
    "                (stimulation_data_df['stimulation_ids'] == stim_id)\n",
    "            ]\n",
    "            stim_data_pre = stim_data.iloc[:pre_trials] # grabs all the rows up to the pre_trials value \n",
    "            stim_data_post = stim_data.iloc[-post_trials:] # grabs all the rows from the end of the dataframe to the post_trials value\n",
    "\n",
    "            # Calculate and plot the mean PSTH for the pre epoch\n",
    "            mean_psth_pre = calculate_mean_psth(stim_data_pre, firing_rate_estimates, ch, bin_size)\n",
    "            ax.plot(mean_psth_pre, color='grey', label='Pre')\n",
    "\n",
    "            # Calculate and plot the mean PSTH for the post epoch\n",
    "            mean_psth_post = calculate_mean_psth(stim_data_post, firing_rate_estimates, ch, bin_size)\n",
    "            ax.plot(mean_psth_post, color='blue', label='Post')\n",
    "\n",
    "            ax.set_title(f'Stim ID = {stim_id}')\n",
    "            ax.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def calculate_mean_psth(stim_data, firing_rate_estimates, ch, bin_size):\n",
    "    psth_data = []\n",
    "    for i, onset in enumerate(stim_data['onset_times']):\n",
    "        # Define a time window of 1500ms centered on the stimulus onset (500ms pre-stimulus to 1000ms post-stimulus)\n",
    "        start_bin = int((onset - 0.5) / bin_size)\n",
    "        end_bin = int((onset + 1.0) / bin_size)\n",
    "        \n",
    "        # Get the PSTH data for the current trial\n",
    "        trial_psth = firing_rate_estimates[ch, start_bin:end_bin]\n",
    "        psth_data.append(trial_psth)\n",
    "    \n",
    "    # Ensuring all trials have the same shape by padding with NaNs to the maximum trial length\n",
    "    max_len = max(map(len, psth_data))\n",
    "    psth_data = [np.pad(trial, (0, max_len - len(trial)), 'constant', constant_values=np.nan) for trial in psth_data]\n",
    "\n",
    "    # Calculate the mean PSTH across trials\n",
    "    mean_psth = np.nanmean(np.stack(psth_data), axis=0)\n",
    "        \n",
    "    # Convert firing rate from spikes per bin to spikes per second (Hz)\n",
    "    mean_psth /= bin_size\n",
    "    \n",
    "    return mean_psth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing recording results dataframe from /home/cresp1el-local/Documents/MATLAB/Data/lmc_project_v2/Whisker/SpikeStuff/recording_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your project folder\n",
    "project_folder_path ='/home/cresp1el-local/Documents/MATLAB/Data/lmc_project_v2/Whisker'\n",
    "# Initialize the NeuralAnalysis class with the project folder path\n",
    "analysis = NeuralAnalysis(project_folder_path)\n",
    "analysis.extract_stimulation_data() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>group_name</th>\n",
       "      <th>recording_name</th>\n",
       "      <th>downsampled_path</th>\n",
       "      <th>rms_values</th>\n",
       "      <th>iqr</th>\n",
       "      <th>good_channels</th>\n",
       "      <th>noisy_channels</th>\n",
       "      <th>mua_data_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_2_3093_rec1</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "      <td>[170.52816270803297, 172.8074476873955, 175.11...</td>\n",
       "      <td>4.686566</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14,...</td>\n",
       "      <td>[13]</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_1_3094_rec2</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "      <td>[169.76160010287387, 172.07686648663235, 174.7...</td>\n",
       "      <td>3.035201</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[31]</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_1_3094_rec1</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "      <td>[174.26712509310488, 172.37445379634585, 180.8...</td>\n",
       "      <td>7.463998</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec1</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "      <td>[169.26424775999243, 171.4846387576975, 173.33...</td>\n",
       "      <td>2.762267</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[31]</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec2</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "      <td>[170.05101760301815, 172.9588068684812, 170.34...</td>\n",
       "      <td>3.586824</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[31]</td>\n",
       "      <td>/home/cresp1el-local/Documents/MATLAB/Data/lmc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   group_name        recording_name  \\\n",
       "0           0    Lmc_opsin    lmc_ch_2_3093_rec1   \n",
       "1           1    Lmc_opsin    lmc_ch_1_3094_rec2   \n",
       "2           2    Lmc_opsin    lmc_ch_1_3094_rec1   \n",
       "3           3  Lmc_noopsin  lmc_noch_1_3096_rec1   \n",
       "4           4  Lmc_noopsin  lmc_noch_1_3096_rec2   \n",
       "\n",
       "                                    downsampled_path  \\\n",
       "0  /home/cresp1el-local/Documents/MATLAB/Data/lmc...   \n",
       "1  /home/cresp1el-local/Documents/MATLAB/Data/lmc...   \n",
       "2  /home/cresp1el-local/Documents/MATLAB/Data/lmc...   \n",
       "3  /home/cresp1el-local/Documents/MATLAB/Data/lmc...   \n",
       "4  /home/cresp1el-local/Documents/MATLAB/Data/lmc...   \n",
       "\n",
       "                                          rms_values       iqr  \\\n",
       "0  [170.52816270803297, 172.8074476873955, 175.11...  4.686566   \n",
       "1  [169.76160010287387, 172.07686648663235, 174.7...  3.035201   \n",
       "2  [174.26712509310488, 172.37445379634585, 180.8...  7.463998   \n",
       "3  [169.26424775999243, 171.4846387576975, 173.33...  2.762267   \n",
       "4  [170.05101760301815, 172.9588068684812, 170.34...  3.586824   \n",
       "\n",
       "                                       good_channels noisy_channels  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14,...           [13]   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...           [31]   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...             []   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...           [31]   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...           [31]   \n",
       "\n",
       "                                       mua_data_path  \n",
       "0  /home/cresp1el-local/Documents/MATLAB/Data/lmc...  \n",
       "1  /home/cresp1el-local/Documents/MATLAB/Data/lmc...  \n",
       "2  /home/cresp1el-local/Documents/MATLAB/Data/lmc...  \n",
       "3  /home/cresp1el-local/Documents/MATLAB/Data/lmc...  \n",
       "4  /home/cresp1el-local/Documents/MATLAB/Data/lmc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.recording_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset_times</th>\n",
       "      <th>offset_times</th>\n",
       "      <th>stimulation_ids</th>\n",
       "      <th>group_name</th>\n",
       "      <th>recording_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.523</td>\n",
       "      <td>20.023</td>\n",
       "      <td>4</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_2_3093_rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.202</td>\n",
       "      <td>27.702</td>\n",
       "      <td>4</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_2_3093_rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.451</td>\n",
       "      <td>39.951</td>\n",
       "      <td>3</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_2_3093_rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.759</td>\n",
       "      <td>42.259</td>\n",
       "      <td>2</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_2_3093_rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.476</td>\n",
       "      <td>50.976</td>\n",
       "      <td>1</td>\n",
       "      <td>Lmc_opsin</td>\n",
       "      <td>lmc_ch_2_3093_rec1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>7972.475</td>\n",
       "      <td>7972.975</td>\n",
       "      <td>2</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>7982.583</td>\n",
       "      <td>7983.083</td>\n",
       "      <td>1</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>7988.389</td>\n",
       "      <td>7988.889</td>\n",
       "      <td>4</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>7994.956</td>\n",
       "      <td>7995.456</td>\n",
       "      <td>3</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>8007.913</td>\n",
       "      <td>8008.413</td>\n",
       "      <td>4</td>\n",
       "      <td>Lmc_noopsin</td>\n",
       "      <td>lmc_noch_1_3096_rec2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4971 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      onset_times  offset_times  stimulation_ids   group_name  \\\n",
       "0          19.523        20.023                4    Lmc_opsin   \n",
       "1          27.202        27.702                4    Lmc_opsin   \n",
       "2          39.451        39.951                3    Lmc_opsin   \n",
       "3          41.759        42.259                2    Lmc_opsin   \n",
       "4          50.476        50.976                1    Lmc_opsin   \n",
       "...           ...           ...              ...          ...   \n",
       "4966     7972.475      7972.975                2  Lmc_noopsin   \n",
       "4967     7982.583      7983.083                1  Lmc_noopsin   \n",
       "4968     7988.389      7988.889                4  Lmc_noopsin   \n",
       "4969     7994.956      7995.456                3  Lmc_noopsin   \n",
       "4970     8007.913      8008.413                4  Lmc_noopsin   \n",
       "\n",
       "            recording_name  \n",
       "0       lmc_ch_2_3093_rec1  \n",
       "1       lmc_ch_2_3093_rec1  \n",
       "2       lmc_ch_2_3093_rec1  \n",
       "3       lmc_ch_2_3093_rec1  \n",
       "4       lmc_ch_2_3093_rec1  \n",
       "...                    ...  \n",
       "4966  lmc_noch_1_3096_rec2  \n",
       "4967  lmc_noch_1_3096_rec2  \n",
       "4968  lmc_noch_1_3096_rec2  \n",
       "4969  lmc_noch_1_3096_rec2  \n",
       "4970  lmc_noch_1_3096_rec2  \n",
       "\n",
       "[4971 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.stimulation_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_luciferin_responsive_electrodes(recording_results_df, stimulation_data_df, n_channels, bin_size=0.001):\n",
    "    # Define the timestamps for when luciferin was added for each recording\n",
    "    luciferin_timestamps = {\n",
    "        'lmc_ch_1_3094_rec1': 4.076459533333333e+03,\n",
    "        'lmc_ch_1_3094_rec2': 4.082218733333333e+03,\n",
    "        'lmc_ch_2_3093_rec1': 4.076533433333334e+03,\n",
    "        'lmc_noch_1_3096_rec1': 4.080881200000000e+03,\n",
    "        'lmc_noch_1_3096_rec2': 4.088738733333333e+03,\n",
    "    }\n",
    "    \n",
    "    # Iterate over unique recording names\n",
    "    for recording_name in recording_results_df['recording_name'].unique():\n",
    "        \n",
    "        print(f\"Estimating firing rates for {recording_name}...\")\n",
    "        # Get the firing rate estimates for the current recording using the estimate_instantaneous_firing_rate function\n",
    "        firing_rate_estimates = estimate_instantaneous_firing_rate(recording_name, recording_results_df, n_channels)\n",
    "        \n",
    "        print(f\"Analyzing {recording_name}...\")\n",
    "        luciferin_responsive_channels = []\n",
    "\n",
    "        # Existing data retrieval logic\n",
    "        good_channels = recording_results_df.loc[\n",
    "            recording_results_df['recording_name'] == recording_name, \n",
    "            'good_channels'\n",
    "        ].values[0]\n",
    "        noisy_channels = recording_results_df.loc[\n",
    "            recording_results_df['recording_name'] == recording_name, \n",
    "            'noisy_channels'\n",
    "        ].values[0]\n",
    "        good_channels = [ch for ch in good_channels if ch not in noisy_channels]\n",
    "\n",
    "        # Fetch the time when luciferin was added for the current recording\n",
    "        luciferin_time = luciferin_timestamps.get(recording_name, None)\n",
    "        if luciferin_time is None:\n",
    "            print(f\"No luciferin timestamp found for {recording_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        for ch in good_channels:\n",
    "            all_baseline_data = []\n",
    "            all_luciferin_data = []\n",
    "\n",
    "            # Filter data for stimulations with ID == 1\n",
    "            stim_data_all = stimulation_data_df[\n",
    "                (stimulation_data_df['recording_name'] == recording_name) &\n",
    "                (stimulation_data_df['stimulation_ids'] == 1)\n",
    "            ]\n",
    "            # Define 'n' as the number of trials you want to consider\n",
    "            n = 30  # Or any other number \n",
    "            \n",
    "            # Filter pre- and post-luciferin data\n",
    "            stim_data_pre = stim_data_all[stim_data_all['onset_times'] < luciferin_time].head(n)\n",
    "            stim_data_post = stim_data_all[stim_data_all['onset_times'] > luciferin_time].tail(n)\n",
    "            \n",
    "            # Collect data for baseline (pre-luciferin)\n",
    "            for onset in stim_data_pre['onset_times']:\n",
    "                start_bin = int(onset / bin_size)\n",
    "                end_bin = int( (onset + 0.5) / bin_size)\n",
    "                # print(f\"Start bin for baseline: {start_bin}, End bin for baseline: {end_bin}\")\n",
    "                # baseline_data = np.mean(firing_rate_estimates[ch, start_bin:end_bin])\n",
    "                # Instead of np.mean, use np.nanmean\n",
    "                baseline_data = np.nanmean(firing_rate_estimates[ch, start_bin:end_bin])\n",
    "                all_baseline_data.append(baseline_data)\n",
    "\n",
    "            # Collect data for post-luciferin\n",
    "            for onset in stim_data_post['onset_times']:\n",
    "                start_bin = int(onset / bin_size)\n",
    "                end_bin = int( (onset+0.5) / bin_size)\n",
    "                # print(f\"Start bin for post-luciferin: {start_bin}, End bin for post-luciferin: {end_bin}\")\n",
    "                # luciferin_data = np.mean(firing_rate_estimates[ch, start_bin:end_bin])\n",
    "                # Instead of np.mean, use np.nanmean\n",
    "                luciferin_data = np.nanmean(firing_rate_estimates[ch, start_bin:end_bin])\n",
    "                all_luciferin_data.append(luciferin_data)\n",
    "            \n",
    "            # Perform bootstrap analysis for 99% CI\n",
    "            baseline_bootstrap = bootstrap_ci(np.array(all_baseline_data), ci=0.99)\n",
    "            luciferin_bootstrap = bootstrap_ci(np.array(all_luciferin_data), ci=0.99)\n",
    "\n",
    "            # Check if luciferin-responsive\n",
    "            if luciferin_bootstrap[0] > baseline_bootstrap[1]:\n",
    "                luciferin_responsive_channels.append(ch)\n",
    "\n",
    "        print(f\"Luciferin-responsive channels for {recording_name}: {luciferin_responsive_channels}\")\n",
    "\n",
    "# Call the function\n",
    "calculate_luciferin_responsive_electrodes(analysis.recording_results_df, analysis.stimulation_data_df, analysis.n_channels, bin_size=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
